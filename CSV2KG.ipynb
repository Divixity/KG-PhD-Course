{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "General approach:\n",
    "1. For each PK cell in the table, get the top 3 entities from Wikidata.\n",
    "2. For each other cell in the table, get the relations and objects for each of the top 3 entities.\n",
    "3. For each column, get the most common relation.\n",
    "4. For each column, get the object that has the most common relation with the PK cell.\n",
    "5. For the PK column, get the most common type.\n",
    "\n",
    "The code is a bit messy with a lot of loop, however, it does work. The results are fine, but there sure are improvements to be made.\n",
    "\n",
    "The is likely some errors in the TP, FP, FN calculations, but the correct/incorrect counts are correct."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dea173702c9b135f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T13:40:50.864890Z",
     "start_time": "2024-04-30T13:40:50.847912Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from lookup import WikidataAPI\n",
    "from endpoints import WikidataEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Query to return matches for object and relation given value from a QID\n",
    "def get_relation_object_query(QID, value):\n",
    "    if isinstance(value, str):\n",
    "        filter_string = f'FILTER(?object = \"{value}\").'\n",
    "    else:\n",
    "        filter_string = f'FILTER(?object = {value}).'\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?relation ?object\n",
    "    WHERE {{\n",
    "      {{\n",
    "        wd:{QID} ?relation ?object.\n",
    "        ?object rdfs:label \"{value}\"@en.\n",
    "      }}\n",
    "      UNION\n",
    "      {{\n",
    "        wd:{QID} ?relation ?object.\n",
    "        {filter_string}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "class CSV2KG:\n",
    "    def __init__(self, df):\n",
    "        self.wikidata = WikidataAPI()\n",
    "        self.ep = WikidataEndpoint()\n",
    "        self.df = df\n",
    "        self.df_candidates = None\n",
    "        self.df_relations = None\n",
    "        self.df_entities = None\n",
    "        self.df_classes = None\n",
    "        \n",
    "    def get_candidates(self):\n",
    "        dataframe = pd.DataFrame(columns=self.df.columns, dtype=object)#self.df.copy()\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            search_string = row.iloc[0]\n",
    "            \n",
    "            # Entities\n",
    "            entities = self.wikidata.getKGEntities(query=search_string, \n",
    "                                      limit=3, \n",
    "                                      type=\"item\")\n",
    "            \n",
    "            dataframe.at[idx, self.df.columns[0]] = entities\n",
    "            \n",
    "                \n",
    "            for search_idx in row.index[1:]:\n",
    "                search_obj_dict = {}\n",
    "                search_obj = row[search_idx]\n",
    "                \n",
    "                if search_obj == search_obj:  # Check if it is not NaN\n",
    "                \n",
    "                    for entity in entities:\n",
    "                        QID = entity.getId().split(\"/\")[-1]\n",
    "                        \n",
    "                        query = get_relation_object_query(QID, search_obj)\n",
    "                        results = self.ep.getQueryResults(query)\n",
    "                        \n",
    "                        rel_obj_list = []\n",
    "                        if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "                            for res in results[\"results\"][\"bindings\"]:\n",
    "                                rel = res[\"relation\"][\"value\"]\n",
    "                                obj = res[\"object\"][\"value\"]\n",
    "                                rel_obj_list.append((rel, obj))\n",
    "                                \n",
    "                        search_obj_dict[entity.getId()] = rel_obj_list\n",
    "\n",
    "                dataframe.at[idx, search_idx] = search_obj_dict\n",
    "        \n",
    "        self.df_candidates = dataframe\n",
    "    \n",
    "    \n",
    "    def get_relations(self):\n",
    "        counts = {}\n",
    "        for col in self.df_candidates.columns[1:]:\n",
    "            relation_counts = {}\n",
    "            for idx, row in self.df_candidates.iterrows():\n",
    "                for entity, search_obj_dict in row[col].items():\n",
    "                    for rel, obj in search_obj_dict:\n",
    "                        relation_counts[rel] = relation_counts.get(rel, 0) + 1\n",
    "            counts[col] = relation_counts\n",
    "            \n",
    "        self.df_relations = pd.DataFrame(columns=self.df.columns)\n",
    "        for col, rel_counts in counts.items():\n",
    "            relation = max(rel_counts, key=rel_counts.get)\n",
    "            self.df_relations.at[0, col] = relation\n",
    "            \n",
    "    def get_entities(self):\n",
    "        self.df_entities = pd.DataFrame(columns=self.df.columns, index=self.df.index)\n",
    "        for idx, row in self.df_candidates.iterrows():\n",
    "            for col in self.df_candidates.columns[1:]:\n",
    "                for entity, search_obj_dict in row[col].items():\n",
    "                    if self.df_relations.at[0, col] in [rel for rel, obj in search_obj_dict]:\n",
    "                        if self.df_entities.at[idx, self.df_entities.columns[0]] != self.df_entities.at[idx, self.df_entities.columns[0]]:\n",
    "                            self.df_entities.at[idx, self.df_entities.columns[0]] = entity\n",
    "        \n",
    "        for idx, row in self.df_entities.iterrows():\n",
    "            for col in self.df_entities.columns[1:]:\n",
    "                subject = self.df_entities.at[idx, self.df_entities.columns[0]]\n",
    "                \n",
    "                if subject == subject:\n",
    "                    for prop, obj in self.df_candidates.at[idx, col].get(subject, []):\n",
    "                        if prop == self.df_relations.at[0, col]:\n",
    "                            self.df_entities.at[idx, col] = obj\n",
    "                            \n",
    "    def get_types(self):\n",
    "        self.df_classes = pd.DataFrame(columns=self.df.columns)\n",
    "        \n",
    "        types_dct = {}\n",
    "        for idx, row in self.df_candidates.iterrows():\n",
    "            entites = row.iloc[0]\n",
    "            for entity in entites:\n",
    "                types = self.ep.getTypesForEntity(entity.getId())\n",
    "                for t in types:\n",
    "                    types_dct[t] = types_dct.get(t, 0) + 1\n",
    "            \n",
    "        type_entity = max(types_dct, key=types_dct.get)\n",
    "        self.df_classes.at[0, self.df_classes.columns[0]] = type_entity\n",
    "        \n",
    "        for col in self.df_entities.columns[1:]:\n",
    "            types_dct = {}\n",
    "            for idx, row in self.df_entities.iterrows():\n",
    "                entity = row[col]\n",
    "                if entity == entity:\n",
    "                    types = self.ep.getTypesForEntity(entity.split(\"/\")[-1])\n",
    "                    for t in types:\n",
    "                        types_dct[t] = types_dct.get(t, 0) + 1\n",
    "            \n",
    "            if types_dct:\n",
    "                type_entity = max(types_dct, key=types_dct.get)\n",
    "                self.df_classes.at[0, col] = type_entity    \n",
    "        \n",
    "    \n",
    "    def run_alignment(self):\n",
    "        self.get_candidates()\n",
    "        self.get_relations()\n",
    "        self.get_entities()\n",
    "        self.get_types()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:30:13.821899Z",
     "start_time": "2024-04-29T08:30:13.805363Z"
    }
   },
   "id": "acc50a9af218fdfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run for 5 tables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7ecb69179fc3aba"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Download the data from https://github.com/sem-tab-challenge/2024/blob/main/data/WikidataTables2024R1.tar.gz\n",
    "path_to_tables = './data/WikidataTables2024R1/DataSets/Valid/tables/'\n",
    "file_names = os.listdir(path_to_tables)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-29T08:30:13.823332Z"
    }
   },
   "id": "1cd0cb83b69f7a87"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y3OHOKFF.csv\n",
      "Y4OS3SBS.csv\n",
      "RQT6VSWL.csv\n",
      "NGT7C6EO.csv\n",
      "BAJ5LMX3.csv\n",
      "VQHPBH3L.csv\n",
      "BDWQF2CN.csv\n",
      "KPFFDB6X.csv\n",
      "4OH908JW.csv\n",
      "OJHKRXI7.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for file_name in file_names[:10]:\n",
    "    df = pd.read_csv(path_to_tables + file_name)\n",
    "    mappings = CSV2KG(df)\n",
    "    mappings.run_alignment()\n",
    "    results.append([file_name, mappings])\n",
    "    print(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.730432Z",
     "start_time": "2024-04-29T08:30:13.825280Z"
    }
   },
   "id": "9aebc345d26ff58c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CEA (Cell-Entity Annotation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e4ceb82be5b603"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cea = pd.read_csv(\"./data/WikidataTables2024R1/DataSets/Valid/gt/cea_gt.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.767468Z",
     "start_time": "2024-04-29T08:31:06.742184Z"
    }
   },
   "id": "c1744ff83479e239"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y3OHOKFF.csv\n",
      "  Correct: 2, Incorrect: 4\n",
      "  Precision: 1.0,  Recall: 0.3333333333333333,  F1: 0.5\n",
      "Y4OS3SBS.csv\n",
      "  Correct: 3, Incorrect: 4\n",
      "  Precision: 1.0,  Recall: 0.42857142857142855,  F1: 0.6\n",
      "RQT6VSWL.csv\n",
      "  Correct: 7, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 1.0\n",
      "NGT7C6EO.csv\n",
      "  Correct: 6, Incorrect: 3\n",
      "  Precision: 1.0,  Recall: 0.6666666666666666,  F1: 0.8\n",
      "BAJ5LMX3.csv\n",
      "  Correct: 10, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 1.0\n",
      "VQHPBH3L.csv\n",
      "  Correct: 8, Incorrect: 6\n",
      "  Precision: 0.5714285714285714,  Recall: 0.5714285714285714,  F1: 0.5714285714285714\n",
      "BDWQF2CN.csv\n",
      "  Correct: 2, Incorrect: 1\n",
      "  Precision: 1.0,  Recall: 0.6666666666666666,  F1: 0.8\n",
      "KPFFDB6X.csv\n",
      "  Correct: 7, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 1.0\n",
      "4OH908JW.csv\n",
      "  Correct: 2, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 1.0\n",
      "OJHKRXI7.csv\n",
      "  Correct: 1, Incorrect: 2\n",
      "  Precision: 1.0,  Recall: 0.3333333333333333,  F1: 0.5\n"
     ]
    }
   ],
   "source": [
    "for res_no in range(len(results)):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    precision_reduction = 0\n",
    "    subset_df = cea[cea[0] == results[res_no][0].removesuffix('.csv')]\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        mapping = results[res_no][1].df_entities.iloc[row[1] - 1, row[2]]\n",
    "        if mapping == row[3]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            if mapping == mapping:\n",
    "                precision_reduction += 1\n",
    "            incorrect += 1\n",
    "    print(f\"{results[res_no][0]}\\n  Correct: {correct}, Incorrect: {incorrect}\")\n",
    "    precision = correct / (correct + precision_reduction)\n",
    "    recall = correct / len(subset_df)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"  Precision: {precision},  Recall: {recall},  F1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.793858Z",
     "start_time": "2024-04-29T08:31:06.750Z"
    }
   },
   "id": "d62c70286927ac9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CTA (Column-Type Annotation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb460737e7e38147"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cta = pd.read_csv(\"./data/WikidataTables2024R1/DataSets/Valid/gt/cta_gt.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.795007Z",
     "start_time": "2024-04-29T08:31:06.772410Z"
    }
   },
   "id": "eec16fe923fdbdc1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "           0  1                                         2\n76  Y3OHOKFF  0  http://www.wikidata.org/entity/Q25110269\n77  Y3OHOKFF  1  http://www.wikidata.org/entity/Q20970434",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>76</th>\n      <td>Y3OHOKFF</td>\n      <td>0</td>\n      <td>http://www.wikidata.org/entity/Q25110269</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Y3OHOKFF</td>\n      <td>1</td>\n      <td>http://www.wikidata.org/entity/Q20970434</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cta[cta[0] == results[0][0].removesuffix('.csv')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.797141Z",
     "start_time": "2024-04-29T08:31:06.779812Z"
    }
   },
   "id": "e91e7c76ef024a9e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      col0 col1 col2\n0  http://www.wikidata.org/entity/Q7725634  NaN  NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col0</th>\n      <th>col1</th>\n      <th>col2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://www.wikidata.org/entity/Q7725634</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][1].df_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.832287Z",
     "start_time": "2024-04-29T08:31:06.790692Z"
    }
   },
   "id": "eb73ca4f1034fd11"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y3OHOKFF.csv\n",
      "  Correct: 0, Incorrect: 2\n",
      "  Precision: 0.0,  Recall: 0.0,  F1: 0.0\n",
      "Y4OS3SBS.csv\n",
      "  Correct: 0, Incorrect: 1\n",
      "  Precision: 0.0,  Recall: 0.0,  F1: 0.0\n",
      "RQT6VSWL.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "NGT7C6EO.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "BAJ5LMX3.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "VQHPBH3L.csv\n",
      "  Correct: 0, Incorrect: 2\n",
      "  Precision: 0.0,  Recall: 0.0,  F1: 0.0\n",
      "BDWQF2CN.csv\n",
      "  Correct: 1, Incorrect: 1\n",
      "  Precision: 1.0,  Recall: 0.5,  F1: 0.6666666666662222\n",
      "KPFFDB6X.csv\n",
      "  Correct: 0, Incorrect: 3\n",
      "  Precision: 0.0,  Recall: 0.0,  F1: 0.0\n",
      "4OH908JW.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "OJHKRXI7.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n"
     ]
    }
   ],
   "source": [
    "for res_no in range(len(results)):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    precision_reduction = 0\n",
    "    subset_df = cta[cta[0] == results[res_no][0].removesuffix('.csv')]\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        mapping = results[res_no][1].df_classes.iloc[0, row[1]]\n",
    "        if mapping == row[2]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            if mapping == mapping:\n",
    "                precision_reduction += 1\n",
    "            incorrect += 1\n",
    "    print(f\"{results[res_no][0]}\\n  Correct: {correct}, Incorrect: {incorrect}\")\n",
    "    precision = correct / (correct + precision_reduction)\n",
    "    recall = correct / len(subset_df)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall+ 1e-12)\n",
    "    print(f\"  Precision: {precision},  Recall: {recall},  F1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.867566Z",
     "start_time": "2024-04-29T08:31:06.798022Z"
    }
   },
   "id": "a9dbb36a157fa048"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CPA (Columns-Property Annotation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28baf8c99ebfde17"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cpa = pd.read_csv(\"./data/WikidataTables2024R1/DataSets/Valid/gt/cpa_gt.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:06.868910Z",
     "start_time": "2024-04-29T08:31:06.800270Z"
    }
   },
   "id": "869b779464d9b60c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y3OHOKFF.csv\n",
      "  Correct: 1, Incorrect: 1\n",
      "  Precision: 0.5,  Recall: 0.5,  F1: 0.49999999999949996\n",
      "Y4OS3SBS.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "RQT6VSWL.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "NGT7C6EO.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "BAJ5LMX3.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "VQHPBH3L.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "BDWQF2CN.csv\n",
      "  Correct: 1, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "KPFFDB6X.csv\n",
      "  Correct: 2, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "4OH908JW.csv\n",
      "  Correct: 2, Incorrect: 0\n",
      "  Precision: 1.0,  Recall: 1.0,  F1: 0.9999999999995\n",
      "OJHKRXI7.csv\n",
      "  Correct: 0, Incorrect: 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m         incorrect \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults[res_no][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  Correct: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcorrect\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Incorrect: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mincorrect\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m precision \u001B[38;5;241m=\u001B[39m \u001B[43mcorrect\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorrect\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mprecision_reduction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m recall \u001B[38;5;241m=\u001B[39m correct \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(subset_df)\n\u001B[1;32m     17\u001B[0m f1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m (precision \u001B[38;5;241m*\u001B[39m recall) \u001B[38;5;241m/\u001B[39m (precision \u001B[38;5;241m+\u001B[39m recall\u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-12\u001B[39m)\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for res_no in range(len(results)):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    precision_reduction = 0\n",
    "    subset_df = cpa[cpa[0] == results[res_no][0].removesuffix('.csv')]\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        mapping = results[res_no][1].df_relations.iloc[row[1], row[2]]\n",
    "        if mapping == row[3]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            if mapping == mapping:\n",
    "                precision_reduction += 1\n",
    "            incorrect += 1\n",
    "    print(f\"{results[res_no][0]}\\n  Correct: {correct}, Incorrect: {incorrect}\")\n",
    "    precision = correct / (correct + precision_reduction)\n",
    "    recall = correct / len(subset_df)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall+ 1e-12)\n",
    "    print(f\"  Precision: {precision},  Recall: {recall},  F1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:31:07.219424Z",
     "start_time": "2024-04-29T08:31:06.808175Z"
    }
   },
   "id": "39d5f3dc800a3263"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-29T08:31:06.953089Z"
    }
   },
   "id": "e27dc4709e59c22c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
